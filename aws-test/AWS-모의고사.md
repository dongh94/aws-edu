# AWS 시험 모의고사 - 해설 (by examtopic)

9/24(10), 



Q1. 한 회사가 여러 대륙에 걸쳐 있는 도시의 온도, 습도, 기압에 대한 데이터를 수집합니다. 회사가 각 사이트에서 매일 수집하는 평균 데이터 양은 500GB입니다. 각 사이트에는 고속 인터넷 연결이 있습니다.
이 회사는 이러한 모든 글로벌 사이트의 데이터를 가능한 한 빨리 단일 Amazon S3 버킷에 집계하려고 합니다. 솔루션은 **운영 복잡성을 최소화**해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

- A. 대상 S3 버킷에서 S3 Transfer Acceleration을 켭니다. 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 업로드합니다. 
- B. 각 사이트의 데이터를 가장 가까운 리전의 S3 버킷으로 업로드합니다. S3 크로스 리전 복제를 사용하여 객체를 대상 S3 버킷으로 복사합니다. 그런 다음 원본 S3 버킷에서 데이터를 제거합니다.
- C. AWS Snowball Edge Storage Optimized 장치 작업을 매일 예약하여 각 사이트에서 가장 가까운 리전으로 데이터를 전송합니다. S3 크로스 리전 복제를 사용하여 객체를 대상 S3 버킷으로 복사합니다.
- D. 각 사이트의 데이터를 가장 가까운 리전의 Amazon EC2 인스턴스로 업로드합니다. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 정기적으로 EBS 스냅샷을 찍어 대상 S3 버킷이 있는 리전에 복사합니다. 해당 리전에서 EBS 볼륨을 복원합니다.



> A1 . 일반 라인: 여러 대륙에 걸쳐 엄청난 양의 파일을 수집합니다.조건: 고속 인터넷 연결 작업: 모든 데이터를 단일 S3 버킷에 집계합니다.요구 사항: 가능한 한 빠르게, 운영 복잡성을 최소화합니다.정답 A: S3 전송 가속화 이유: - 이상적으로는 장거리 전송을 위한 객체와 함께 작동합니다(Edge Locations 사용) - S3와의 콘텐츠 전송 속도를 최대 50-500%까지 높일 수 있습니다.사용 사례: 모바일 및 웹 애플리케이션 업로드 및 다운로드, 분산 사무실 이전, 신뢰할 수 있는 파트너와의 데이터 교환.일반적으로 회사 간에 대규모 데이터 세트를 공유하는 경우 고객은 가속 업로드로 S3 버킷에 대한 특별 액세스를 설정하여 데이터 교환 및 혁신 속도를 높일 수 있습니다.B - 재해 복구에 대한 정보C - 로컬 환경과 AWS 클라우드 간의 데이터 전송에 대한 정보D - 재해 복구에 대한 정보 : A

---



Q2. 회사는 자체 애플리케이션의 로그 파일을 분석할 수 있는 기능이 필요합니다. 로그는 Amazon S3 버킷에 JSON 형식으로 저장됩니다. **쿼리는 간단하며 주문형으로 실행**됩니다. 솔루션 아키텍트는 기존 아키텍처를 **최소한으로 변경**하여 분석을 수행해야 합니다. 솔루션
아키텍트는 **최소한의 운영 오버헤드**로 이러한 요구 사항을 충족하기 위해 무엇을 해야 할까요?

- A. Amazon Redshift를 사용하여 모든 콘텐츠를 한곳에 로드하고 필요에 따라 SQL 쿼리를 실행합니다.
- B. Amazon CloudWatch Logs를 사용하여 로그를 저장합니다. 필요에 따라 Amazon CloudWatch 콘솔에서 SQL 쿼리를 실행합니다.
- C. 필요에 따라 Amazon Athena를 Amazon S3와 직접 함께 사용하여 쿼리를 실행합니다.
- D. AWS Glue를 사용하여 로그를 카탈로그화합니다. Amazon EMR에서 일시적인 Apache Spark 클러스터를 사용하여 필요에 따라 SQL 쿼리를 실행합니다.



> A2. 키워드: - 쿼리는 간단하며 주문형으로 실행됩니다. - 기존 아키텍처에 최소한의 변경이 필요합니다. A: 오답 - 2단계를 거쳐야 합니다. 모든 콘텐츠를 Redshift에 로드하고 SQL 쿼리를 실행합니다(이것은 간단한 쿼리이므로 Athena를 사용할 수 있고 복잡한 쿼리의 경우 Redshit을 적용합니다) B: 오답 - 쿼리는 주문형으로 실행되므로 CloudWatch Logs를 사용하여 로그를 저장할 필요가 없습니다. C: 정답 - 이것은 간단한 쿼리이므로 Athena를 S3에 직접 적용할 수 있습니다. D: 오답 - 2단계가 필요합니다. AWS Glue를 사용하여 로그를 카탈로그화하고 Spark를 사용하여 SQL 쿼리를 실행합니다. : C

---

Q3. 한 회사에서는 AWS Organizations를 사용하여 여러 부서의 여러 AWS 계정을 관리합니다. 관리 계정에는 프로젝트 보고서가 포함된 Amazon S3 버킷이 있습니다. 이 회사는 이 S3 버킷에 대한 액세스를 AWS Organizations의 조직 내 계정 사용자로만 제한하려고 합니다.
어떤 솔루션이 **운영 오버헤드를 최소화**하면서 이러한 요구 사항을 충족합니까?

- A. 조직 ID에 대한 참조가 있는 aws PrincipalOrgID 글로벌 조건 키를 S3 버킷 정책에 추가합니다.
- B. 각 부서에 대한 조직 단위(OU)를 만듭니다. S3 버킷 정책에 aws:PrincipalOrgPaths 글로벌 조건 키를 추가합니다.
- C. AWS CloudTrail을 사용하여 CreateAccount, InviteAccountToOrganization, LeaveOrganization 및 RemoveAccountFromOrganization 이벤트를 모니터링합니다. 이에 따라 S3 버킷 정책을 업데이트합니다.
- D. S3 버킷에 액세스해야 하는 각 사용자를 태그합니다. aws:PrincipalTag 글로벌 조건 키를 S3 버킷 정책에 추가합니다.



> A3. https://docs.aws.amazon.com/organizations/latest/userguide/orgs_permissions_overview.html 조건 키: AWS는 특정 작업에 대한 보다 세부적인 제어를 제공하기 위해 쿼리할 수 있는 조건 키를 제공합니다. 다음 조건 키는 AWS Organizations에서 특히 유용합니다. aws:PrincipalOrgID - 리소스 기반 정책에서 Principal 요소를 지정하는 것을 간소화합니다. 이 글로벌 키는 조직의 모든 AWS 계정에 대한 모든 계정 ID를 나열하는 대안을 제공합니다. 조직의 구성원인 모든 계정을 나열하는 대신 Condition 요소에서 조직 ID를 지정할 수 있습니다. aws:PrincipalOrgPaths - 이 조건 키를 사용하여 특정 조직 루트, OU 또는 해당 자식의 구성원을 일치시킵니다. aws:PrincipalOrgPaths 조건 키는 요청을 하는 주체(루트 사용자, IAM 사용자 또는 역할)가 지정된 조직 경로에 있는 경우 true를 반환합니다. 경로는 AWS Organizations 엔터티의 구조를 텍스트로 표현한 것입니다. : A

---

Q4. 애플리케이션은 VPC의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon S3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷에 연결하지 않고도 S3 버킷에 액세스해야 합니다.
어떤 솔루션이 Amazon S3에 프라이빗 네트워크 연결을 제공할까요?

- A. S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다.
- B. 로그를 Amazon CloudWatch Logs로 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다.
- C. S3 액세스를 허용하기 위해 Amazon EC2에 인스턴스 프로필을 생성합니다.
- D. S3 엔드포인트에 액세스하기 위한 개인 링크가 있는 Amazon API Gateway API를 생성합니다.



> A4. 키워드: - VPC의 EC2 - EC2 인스턴스는 인터넷에 연결하지 않고도 S3 버킷에 액세스해야 함 A: 정답 - Gateway VPC 엔드포인트는 추가 비용 없이 S3 버킷에 비공개로 연결할 수 있음 B: 오답 - EC2에서 CloudWatch로 프라이빗 네트워크에 대한 CloudWatch Logs에 대한 인터페이스 VPC 엔드포인트를 설정할 수 있음. 하지만 CloudWatch에서 S3 버킷으로: 로그 데이터는 내보낼 수 있을 때까지 최대 12시간이 걸릴 수 있으며 요구 사항은 EC2에서 S3로만 필요함 C: 오답 - 인스턴스 프로필을 만들어 액세스 권한만 부여하고 EC2가 S3에 비공개로 연결할 수 있도록 돕지 않음 D: 오답 - 프록시와 같은 API Gateway는 외부 사이트에서 네트워크를 수신하고 AWS Lambda, Amazon EC2, 애플리케이션 로드 밸런서 또는 클래식 로드 밸런서와 같은 Elastic Load Balancing 제품, Amazon DynamoDB, Amazon Kinesis 또는 공개적으로 사용 가능한 HTTPS 기반 엔드포인트로 요청을 전달함. 하지만 S3는 아님 : A

---

Q5. 한 회사가 사용자가 업로드한 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 더 나은 확장성과 가용성을 위해 회사는 아키텍처를 복제하고 다른 가용성 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 만들어 둘 다 애플리케이션 로드 밸런서 뒤에 배치했습니다. 이 변경을 완료한 후, 사용자들은 웹사이트를 새로 고칠 때마다 문서의 하위 집합 중 하나 또는 다른 하나를 볼 수 있지만 모든 문서를 동시에 볼 수는 없다고 보고했습니다. 솔루션 아키텍트는 사용자가 모든 문서를 한 번에 볼 수 있도록 하기 위해 무엇을 제안해야 할까요?

- A. 두 EBS 볼륨 모두에 모든 문서가 포함되도록 데이터를 복사합니다.
- B. 사용자를 문서가 있는 서버로 안내하도록 애플리케이션 로드 밸런서를 구성합니다.
- C. 두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 새 문서를 Amazon EFS에 저장하도록 애플리케이션을 수정합니다.
- D. 두 서버 모두에 요청을 보내도록 애플리케이션 로드 밸런서를 구성합니다. 올바른 서버에서 각 문서를 반환합니다.



> A5. 사용자가 모든 문서를 한 번에 볼 수 있도록 하려면 솔루션 아키텍트가 옵션 C를 제안해야 합니다. 두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 애플리케이션을 수정하여 새 문서를 Amazon EFS에 저장합니다. 옵션 C는 두 EBS 볼륨의 데이터를 Amazon Elastic File System(EFS)으로 복사하고 애플리케이션을 수정하여 새 문서를 EFS에 저장합니다. Amazon EFS는 여러 EC2 인스턴스에서 동시에 파일을 저장하고 액세스할 수 있는 완벽하게 관리되는 확장 가능한 파일 스토리지 서비스입니다. 데이터를 EFS로 이동하고 애플리케이션을 수정하여 새 문서를 EFS에 저장하면 애플리케이션이 단일 중앙 위치에서 모든 문서에 액세스할 수 있으므로 사용자가 모든 문서를 한 번에 볼 수 있습니다. 전반적으로 옵션 C는 사용자가 모든 문서를 한 번에 볼 수 있도록 하는 데 가장 효과적인 솔루션입니다.

---

Q6. 한 회사가 NFS를 사용하여 온프레미스 네트워크 연결 스토리지에 대용량 비디오 파일을 저장합니다. 각 비디오 파일의 크기는 1MB에서 500GB까지입니다. 총 스토리지는 70TB이며 더 이상 증가하지 않습니다. 회사는 비디오 파일을 Amazon S3로 마이그레이션하기로 결정했습니다. 회사는 가능한 한 빨리 비디오 파일을 마이그레이션해야 하며 가능한 한 최소한의 네트워크 대역폭을 사용해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

- A. S3 버킷을 만듭니다. S3 버킷에 쓸 수 있는 권한이 있는 IAM 역할을 만듭니다. AWS CLI를 사용하여 모든 파일을 로컬로 S3 버킷에 복사합니다.
- B. AWS Snowball Edge 작업을 만듭니다. 온프레미스에서 Snowball Edge 장치를 받습니다. Snowball Edge 클라이언트를 사용하여 데이터를 장치로 전송합니다. AWS가 Amazon S3로 데이터를 가져올 수 있도록 장치를 반환합니다.
- C. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 퍼블릭 서비스 엔드포인트를 만듭니다. S3 버킷을 만듭니다. S3 파일 게이트웨이에 새 NFS 파일 공유를 만듭니다. 새 파일 공유를 S3 버킷으로 지정합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.
- D. 온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 퍼블릭 가상 인터페이스(VIF)를 만듭니다. S3 버킷을 만듭니다. S3 파일 게이트웨이에 새 NFS 파일 공유를 만듭니다. 새 파일 공유를 S3 버킷으로 지정합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.



> A6. 이 질문은 저장소가 더 이상 증가하지 않는다고 명시합니다. 즉, 어떠한 종류의 데이터 동기화도 할 필요가 없음을 의미합니다. 또한 총 저장소는 70TB로 많은 양의 데이터입니다. 이는 높은 전송 비용을 의미합니다. 따라서 A, C, D 옵션은 무시할 수 있습니다. 정답: A. Snowball 장치는 대용량 데이터 전송을 지원하는 물리적 저장 장치입니다. 일반적으로 온프레미스에서 AWS로 엄청난 양의 데이터를 전송하는 데 사용됩니다. 구체적으로 Snowball Edge는 최대 80TB의 데이터 전송에 적합합니다. 전송 시간은 1~2주 사이이므로 수백 테라바이트의 데이터가 있는 경우 인터넷을 사용하는 것보다 더 빨리 받을 수 있습니다. 페타바이트의 데이터를 전송해야 하는 경우 최대 10PB의 데이터를 전송하는 물리적 트랙인 AWS Snowmobile을 사용하는 것이 좋습니다. 분석해 보겠습니다.B. Snowball Edge 디바이스에서 최대 100Gbps 속도로 파일을 복사할 수 있습니다.70TB는 약 5600초가 걸리므로 매우 빠르게, 2시간도 걸리지 않습니다.단점은 디바이스를 받는 데 4~6일이 걸리고, 다시 보내는 데 2~3일이 더 걸리고 AWS에서 데이터가 S3에 도달하면 데이터를 옮기는 데 걸린다는 것입니다.총 시간: 6~9일.사용 대역폭: 0.C. 파일 게이트웨이는 인터넷을 사용하므로 최대 속도는 최대 1Gbps이므로 최소 6.5일이 걸리고 70TB의 인터넷 대역폭을 사용합니다.D. Direct Connect로 최대 10Gbps의 속도를 달성할 수 있습니다.총 시간 15.5시간이 걸리고 70TB의 대역폭을 사용합니다.그러나 흥미로운 점은 질문에서 어떤 유형의 대역폭을 구체적으로 언급하지 않는다는 것입니다. Direct Connect는 온프레미스와 AWS 클라우드 간에 전용 피어 투 피어 연결이 있으므로 인터넷 대역폭을 사용하지 않으므로 기술적으로 "공용" 대역폭을 사용하지 않습니다. 요구 사항이 약간 모호하지만 B가 가장 적절한 답이라고 생각하지만 대역폭 사용량이 공용 연결에만 엄격하게 적용되는 경우 D도 옳을 수 있습니다. : B

Q7. 어떤 회사에 수신 메시지를 수집하는 애플리케이션이 있습니다. 수십 개의 다른 애플리케이션과 마이크로서비스가 이 메시지를 빠르게 소비합니다. 메시지 수는 **크게 다르고 때로는 초당 100,000개로 갑자기 증가**합니다. 이 회사는 솔루션을 분리하고 **확장성을 높**이려고 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

- A. Amazon Kinesis Data Analytics에 메시지를 유지합니다. 소비자 애플리케이션을 구성하여 메시지를 읽고 처리합니다.
- B. CPU 메트릭에 따라 EC2 인스턴스 수를 확장하기 위해 Auto Scaling 그룹의 Amazon EC2 인스턴스에 수집 애플리케이션을 배포합니다.
- C. 단일 샤드로 Amazon Kinesis Data Streams에 메시지를 씁니다. AWS Lambda 함수를 사용하여 메시지를 사전 처리하고 Amazon DynamoDB에 저장합니다. 소비자 애플리케이션을 구성하여 DynamoDB에서 읽어 메시지를 처리합니다.
- D. 여러 Amazon Simple Queue Service(Amazon SOS) 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시합니다. 소비자 애플리케이션을 구성하여 대기열에서 메시지를 처리합니다.



> A7. 기본적으로 SQS 대기열은 초당 최대 3,000개의 메시지를 처리할 수 있습니다. 그러나 AWS 지원에 문의하여 더 높은 처리량을 요청할 수 있습니다. AWS는 초당 300개 메시지 단위로 기본 제한을 넘어 대기열의 메시지 처리량을 늘릴 수 있으며, 초당 최대 10,000개 메시지까지 늘릴 수 있습니다. 대기열이 처리할 수 있는 초당 최대 메시지 수는 SQS API가 처리할 수 있는 초당 최대 요청 수와 다르다는 점에 유의하는 것이 중요합니다. SQS API는 초당 많은 양의 요청을 처리하도록 설계되었으므로 대기열의 최대 메시지 처리량을 초과하는 속도로 대기열에 메시지를 보내는 데 사용할 수 있습니다. * 키워드: - 메시지 수가 크게 다름 - 때때로 초당 100,000개로 갑자기 증가 A: 오답 - Kinesis Data Analytics와 Kinesis Data Stream을 혼동하지 마세요 =)) Kinesis Data Analytics는 분석 목적으로 Kinesis Data Stream이나 Kinesis Data FireHose 또는 MSK(Apache Kafka용 관리형 스트림)에서 데이터를 가져옵니다. 메시지를 소비하여 애플리케이션으로 보낼 수 없습니다. B: 오답 - 키워드 기준 -> Auto Scaling 그룹은 CPU 메트릭을 확인하고 EC2를 시작하는 데 시간이 필요하고 메시지가 크게 다르기 때문에 잘 확장되지 않습니다. 예: EC2를 10개에서 100개로 확장해야 합니다. 확장하는 동안 서버가 잠시 다운될 수 있습니다. C: 오답 - Kinesis Data Streams는 이 경우를 처리할 수 있지만 샤드를 늘려야 하지만 단일 샤드는 늘려서는 안 됩니다. D: 정답: 팬아웃 패턴 SNS + 여러 SQS를 사용하면 높은 작업 부하를 잘 처리할 수 있습니다. 이는 다음과 같은 사용 사례에 적합합니다. - 메시지 수가 급격히 변하는 경우 - 때때로 초당 100,000개로 갑자기 증가하는 경우 D

Q8. 한 회사가 분산 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 애플리케이션은 **가변적인 워크로드**를 처리합니다. 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버로 구성되어 있습니다. 이 회사는 **복원성과 확장성을 극대화**하는 솔루션으로 애플리케이션을 현대화하려고 합니다.
솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 어떻게 아키텍처를 설계해야 할까요?

- A. Amazon Simple Queue Service(Amazon SQS) 대기열을 작업의 대상으로 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 예약된 스케일링을 사용하도록 EC2 Auto Scaling을 구성합니다.
- B. Amazon Simple Queue Service(Amazon SQS) 대기열을 작업의 대상으로 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 대기열의 크기에 따라 EC2 Auto Scaling을 구성합니다.
- C. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 구현합니다. 작업의 대상으로 AWS CloudTrail을 구성합니다. 기본 서버의 부하에 따라 EC2 Auto Scaling을 구성합니다.
- D. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨트 노드를 구현합니다. 작업의 대상으로 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다. 컴퓨트 노드의 부하에 따라 EC2 Auto Scaling을 구성합니다.



> A8. 복원성과 확장성을 극대화하기 위한 최상의 솔루션은 Amazon SQS 대기열을 작업의 대상으로 사용하는 것입니다. 이렇게 하면 기본 서버와 컴퓨팅 노드가 분리되어 독립적으로 확장할 수 있습니다. 또한 장애 발생 시 작업 손실을 방지하는 데 도움이 됩니다. 컴퓨팅 노드에 Amazon EC2 인스턴스의 자동 확장 그룹을 사용하면 작업 부하에 따라 자동으로 확장할 수 있습니다. 이 경우 기본 서버 또는 컴퓨팅 노드의 부하보다 실제 작업 부하를 더 잘 나타내는 Amazon SQS 대기열의 크기에 따라 자동 확장 그룹을 구성하는 것이 좋습니다. 이 접근 방식을 사용하면 애플리케이션이 가변 작업 부하를 처리할 수 있고 필요에 따라 컴퓨팅 노드를 자동으로 확장하거나 축소하여 비용을 최소화할 수 있습니다 * 키워드: - 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버로 구성됩니다. - 복원성과 확장성을 극대화합니다. A: 오답 - 질문은 높은 작업 부하에 대한 일정에 대해 언급하지 않습니다. 따라서 이 경우 예약된 확장을 사용하지 않습니다. B: 정답 - SQS는 높은 작업 부하의 경우 대기열에 메시지를 보관할 수 있으며, 작업 부하가 너무 높으면 대기열 크기에 따라 EC2 인스턴스를 늘릴 수 있습니다. C: 오답 - AWS CloudTrail은 API 로그이며 AWS 사용자 활동의 감사 로그에 사용됩니다. D: 오답 - 이벤트 브리지는 필터 이벤트 및 트리거 이벤트에 사용됩니다. B

Q9. 한 회사가 데이터 센터에서 SMB 파일 서버를 운영하고 있습니다. 파일 서버는 파일이 생성된 후 처음 며칠 동안 자주 액세스되는 대용량 파일을 저장합니다. 7일 후에는 파일에 거의 액세스하지 않습니다.
총 데이터 크기가 증가하고 있으며 회사의 총 스토리지 용량에 가깝습니다. 솔루션 아키텍트는 가장 최근에 액세스한 파일에 대한 **저지연 액세스를 잃지 않**으면서 회사의 **사용 가능한 스토리지 공간을 늘**려야 합니다. 솔루션 아키텍트는 또한 향후 스토리지 문제를 방지하기 위해 **파일 수명 주기 관리**를 제공해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

- A. AWS DataSync를 사용하여 7일이 지난 데이터를 SMB 파일 서버에서 AWS로 복사합니다.
- B. 회사의 스토리지 공간을 확장하기 위해 Amazon S3 파일 게이트웨이를 만듭니다. 7일 후 S3 Glacier Deep Archive로 데이터를 전환하기 위한 S3 라이프사이클 정책을 만듭니다.
- C. 회사의 저장 공간을 확장하기 위해 Amazon FSx for Windows File Server 파일 시스템을 만듭니다.
- D. 각 사용자의 컴퓨터에 Amazon S3에 액세스하기 위한 유틸리티를 설치합니다. 7일 후 S3 Glacier Flexible Retrieval로 데이터를 전환하기 위한 S3 Lifecycle 정책을 만듭니다.



> A9. Amazon S3 파일 게이트웨이와 S3 라이프사이클 정책을 생성하여 데이터를 S3 Glacier Deep Archive로 전환하면 프롬프트에 지정된 요구 사항을 충족합니다. S3 파일 게이트웨이를 사용하면 SMB 및 NFS와 같은 표준 파일 시스템 프로토콜을 사용하여 Amazon S3에 객체를 저장하고 검색할 수 있습니다. 이렇게 하면 회사 데이터에 대한 추가 저장 공간이 제공되고 데이터가 여전히 SMB 파일 서버에 저장되므로 가장 최근에 액세스한 파일에 대한 저지연 액세스가 가능합니다. B

Q10. 한 회사가 AWS에서 전자상거래 웹 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 새로운 주문에 대한 정보를 Amazon API Gateway REST API로 보내 처리합니다. 이 회사는 주문이 수신된 순서대로 처리되도록 하려고 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

- A. API Gateway 통합을 사용하여 애플리케이션이 주문을 받으면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시합니다. 처리를 수행하기 위해 AWS Lambda 함수를 토픽에 구독합니다.
- B. API Gateway 통합을 사용하여 애플리케이션이 주문을 받으면 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 호출하도록 SQS FIFO 대기열을 구성합니다.
- C. API Gateway 권한 부여자를 사용하여 애플리케이션이 주문을 처리하는 동안 모든 요청을 차단합니다.
- D. API Gateway 통합을 사용하여 애플리케이션이 주문을 받을 때 Amazon Simple Queue Service(Amazon SQS) 표준 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 호출하도록 SQS 표준 대기열을 구성합니다.



> A10. 주문이 수신된 순서대로 처리되도록 하려면 Amazon SQS FIFO(First-In-First-Out) 대기열을 사용하는 것이 가장 좋은 솔루션입니다. 이 유형의 대기열은 메시지를 보내고 받는 정확한 순서를 유지합니다. 이 경우 애플리케이션은 새 주문에 대한 정보를 Amazon API Gateway REST API로 보낼 수 있으며, 그런 다음 API Gateway 통합을 사용하여 Amazon SQS FIFO 대기열로 메시지를 보내 처리할 수 있습니다. 그런 다음 대기열을 구성하여 각 주문에 필요한 처리를 수행하기 위해 AWS Lambda 함수를 호출할 수 있습니다. 이렇게 하면 주문이 수신된 정확한 순서대로 처리됩니다. B 

Q11. 한 회사에는 Amazon EC2 인스턴스에서 실행되고 Amazon Aurora 데이터베이스를 사용하는 애플리케이션이 있습니다. EC2 인스턴스는 로컬 파일에 저장된 사용자 이름과 비밀번호를 사용하여 데이터베이스에 연결합니다. 이 회사는 자격 증명 관리의 운영 오버헤드를 최소화하려고 합니다.
솔루션 아키텍트는 이 목표를 달성하기 위해 무엇을 해야 할까요?

- A. AWS Secrets Manager를 사용합니다. 자동 회전을 켭니다.
- B. AWS Systems Manager Parameter Store를 사용합니다. 자동 회전을 켭니다.
- C. AWS Key Management Service(AWS KMS) 암호화 키로 암호화된 객체를 저장하기 위해 Amazon S3 버킷을 만듭니다. 자격 증명 파일을 S3 버킷으로 마이그레이션합니다. 애플리케이션을 S3 버킷으로 가리킵니다.
- D. 각 EC2 인스턴스에 대해 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 만듭니다. 각 EC2 인스턴스에 새 EBS 볼륨을 연결합니다. 자격 증명 파일을 새 EBS 볼륨으로 마이그레이션합니다. 애플리케이션을 새 EBS 볼륨으로 가리킵니다.



> A11. : AWS Secrets Manager를 사용하고 자동 로테이션을 활성화하는 것은 자격 증명 관리의 운영 오버헤드를 최소화하기 위한 권장 솔루션입니다. AWS Secrets Manager는 데이터베이스 자격 증명과 같은 비밀을 저장하고 관리하기 위한 안전하고 중앙 집중화된 서비스를 제공합니다. Secrets Manager를 활용하면 애플리케이션이 런타임에 데이터베이스 자격 증명을 프로그래밍 방식으로 검색할 수 있으므로 로컬 파일에 저장할 필요가 없습니다. 자동 로테이션을 활성화하면 데이터베이스 자격 증명이 수동 개입 없이 정기적으로 로테이션되어 보안과 규정 준수가 향상됩니다. A

Q12. 글로벌 기업이 애플리케이션 로드 밸런서(ALB) 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 웹 애플리케이션에는 정적 데이터와 동적 데이터가 있습니다. 이 회사는 정적 데이터를 Amazon S3 버킷에 저장합니다. 이 회사는 **정적 데이터와 동적 데이터의 성능을 개선하고 지연 시간을 줄이려**고 합니다. 이 회사는 Amazon Route 53에 등록된 자체 도메인 이름을 사용하고 있습니다.
솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

- A. S3 버킷과 ALB를 오리진으로 하는 Amazon CloudFront 배포를 만듭니다. Route 53을 구성하여 트래픽을 CloudFront 배포로 라우팅합니다.
- B. ALB를 오리진으로 하는 Amazon CloudFront 배포를 만듭니다. S3 버킷을 엔드포인트로 하는 AWS Global Accelerator 표준 가속기를 만듭니다. Route 53을 구성하여 트래픽을 CloudFront 배포로 라우팅합니다.
- C. S3 버킷을 오리진으로 하는 Amazon CloudFront 배포를 만듭니다. ALB와 CloudFront 배포를 엔드포인트로 하는 AWS Global Accelerator 표준 가속기를 만듭니다. 가속기 DNS 이름을 가리키는 사용자 지정 도메인 이름을 만듭니다. 사용자 지정 도메인 이름을 웹 애플리케이션의 엔드포인트로 사용합니다.
- D. ALB를 오리진으로 하는 Amazon CloudFront 배포를 만듭니다. S3 버킷을 엔드포인트로 하는 AWS Global Accelerator 표준 가속기를 만듭니다. 두 개의 도메인 이름을 만듭니다. 한 도메인 이름을 동적 콘텐츠의 CloudFront DNS 이름으로 지정합니다. 다른 도메인 이름을 정적 콘텐츠의 가속기 DNS 이름으로 지정합니다. 도메인 이름을 웹 애플리케이션의 엔드포인트로 사용합니다.



>  S3 버킷과 ALB를 오리진으로 하는 Amazon CloudFront 배포를 만듭니다. Route 53을 구성하여 트래픽을 CloudFront 배포로 라우팅합니다. 이유는 다음과 같습니다. 여러 오리진이 있는 CloudFront: CloudFront를 사용하면 배포에 여러 오리진을 설정할 수 있으므로 ALB(동적 콘텐츠용)와 S3 버킷(정적 콘텐츠용)을 모두 오리진으로 사용할 수 있습니다. 즉, 동적 콘텐츠와 정적 콘텐츠 모두 CloudFront를 통해 제공할 수 있으며, CloudFront는 에지 위치에서 콘텐츠를 캐시하여 지연 시간을 줄입니다. CloudFront와 Route 53 통합: Amazon Route 53은 도메인의 트래픽을 CloudFront 배포로 라우팅하도록 쉽게 구성할 수 있습니다. 사용자는 도메인에 액세스하고 Route 53은 가장 가까운 CloudFront 에지 위치로 안내합니다.,  AWS Global Accelerator는 Amazon CloudFront와 어떻게 다릅니까? A: AWS Global Accelerator와 Amazon CloudFront는 전 세계의 AWS 글로벌 네트워크와 엣지 로케이션을 사용하는 별도의 서비스입니다. CloudFront는 캐시 가능한 콘텐츠(예: 이미지 및 비디오)와 동적 콘텐츠(예: API 가속 및 동적 사이트 제공)의 성능을 모두 개선합니다. Global Accelerator는 하나 이상의 AWS 지역에서 실행되는 애플리케이션에 엣지에서 패킷을 프록시하여 TCP 또는 UDP를 통한 광범위한 애플리케이션의 성능을 개선합니다. Global Accelerator는 게임(UDP), IoT(MQTT), VoIP(Voice over IP)와 같은 HTTP가 아닌 사용 사례와 정적 IP 주소 또는 결정적이고 빠른 지역적 장애 조치가 특별히 필요한 HTTP 사용 사례에 적합합니다. 두 서비스 모두 DDoS 보호를 위해 AWS Shield와 통합됩니다. A

Q13. 한 회사가 AWS 인프라에 대해 월별 유지 관리를 수행합니다. 이러한 유지 관리 활동 중에 회사는 여러 AWS 지역에서 Amazon RDS for MySQL 데이터베이스에 대한 자격 증명을 순환해야 합니다.
어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할까요?

- A. 자격 증명을 AWS Secrets Manager의 비밀로 저장합니다. 필요한 리전에 다중 리전 비밀 복제를 사용합니다. Secrets Manager를 구성하여 일정에 따라 비밀을 순환합니다.
- B. 보안 문자열 매개변수를 생성하여 AWS Systems Manager에서 자격 증명을 비밀로 저장합니다. 필요한 Region에 대해 다중 Region 비밀 복제를 사용합니다. Systems Manager를 구성하여 일정에 따라 비밀을 순환합니다.
- C. 서버 측 암호화(SSE)가 활성화된 Amazon S3 버킷에 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 AWS Lambda 함수를 호출하여 자격 증명을 회전합니다.
- D. AWS Key Management Service(AWS KMS) 다중 지역 고객 관리 키를 사용하여 자격 증명을 비밀로 암호화합니다. Amazon DynamoDB 글로벌 테이블에 비밀을 저장합니다. AWS Lambda 함수를 사용하여 DynamoDB에서 비밀을 검색합니다. RDS API를 사용하여 비밀을 순환합니다.



> A13. 자격 증명을 AWS Secrets Manager에 비밀로 저장하고 필요한 지역에 대해 다중 지역 비밀 복제를 사용하고 Secrets Manager를 구성하여 일정에 따라 비밀을 순환시키는 것으로, 운영 오버헤드를 최소화하면서 요구 사항을 충족합니다. AWS Secrets Manager를 사용하면 데이터베이스 자격 증명과 같은 비밀을 여러 AWS 지역에 저장, 관리 및 순환시킬 수 있습니다. 다중 지역 비밀 복제를 활성화하면 필요한 지역에 비밀을 복제하여 유지 관리 활동 중에 자격 증명을 원활하게 순환시킬 수 있습니다. 또한 Secrets Manager는 일정에 따라 비밀을 자동으로 순환시켜 매월 자격 증명을 순환시키는 운영 오버헤드를 최소화합니다. A

Q14. 한 회사가 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 전자상거래 애플리케이션을 실행합니다. 인스턴스는 여러 가용성 영역에 걸쳐 Amazon EC2 자동 확장 그룹에서 실행됩니다. 자동 확장 그룹은 CPU 사용률 메트릭에 따라 확장됩니다. 전자상거래 애플리케이션은 대규모 EC2 인스턴스에 호스팅된 MySQL 8.0 데이터베이스에 트랜잭션 데이터를 저장합니다.
애플리케이션 부하가 증가함에 따라 데이터베이스 성능이 빠르게 저하됩니다. 애플리케이션은 쓰기 트랜잭션보다 더 많은 **읽기 요청**을 처리합니다. 이 회사는 **높은 가용성을 유지하면서 예측할 수 없는 읽기 워크로드의 수요를 충족**하도록 데이터베이스를 **자동으로 확장**하는 솔루션을 원합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

- A. 리더 및 컴퓨팅 기능에 단일 노드를 갖춘 Amazon Redshift를 사용합니다.
- B. 단일 AZ 배포로 Amazon RDS 사용 다른 가용성 영역에 리더 인스턴스를 추가하도록 Amazon RDS를 구성합니다.
- C. Amazon Aurora를 Multi-AZ 배포와 함께 사용합니다. Aurora Replicas로 Aurora Auto Scaling을 구성합니다.
- D. EC2 스팟 인스턴스와 함께 Memcached에 Amazon ElastiCache를 사용합니다.



> A14. Amazon Aurora를 Multi-AZ 배포와 함께 사용하고 Aurora Replicas로 Aurora Auto Scaling을 구성하는 것이 요구 사항을 충족하는 가장 좋은 솔루션입니다. Aurora는 고성능과 고가용성을 위해 설계된 완벽하게 관리되는 MySQL 호환 관계형 데이터베이스입니다. Aurora Multi-AZ 배포는 다른 가용성 영역에 동기식 대기 복제본을 자동으로 유지하여 고가용성을 제공합니다. 또한 Aurora Auto Scaling을 사용하면 읽기 워크로드에 대응하여 Aurora Replicas 수를 자동으로 확장하여 예측할 수 없는 읽기 워크로드의 수요를 충족하는 동시에 고가용성을 유지할 수 있습니다. 이를 통해 애플리케이션의 수요를 충족하는 동시에 고가용성을 유지하기 위해 데이터베이스를 확장하는 자동화된 솔루션을 제공합니다. C

Q15. 한 회사가 최근 AWS로 마이그레이션했고 프로덕션 **VPC에서 유입되고 유출되는 트래픽을 보호**하는 솔루션을 구현하려고 합니다. 이 회사는 온프레미스 데이터 센터에 검사 서버를 두었습니다. 검사 서버는 **트래픽 흐름 검사 및 트래픽 필터링과 같은 특정 작업**을 수행했습니다. 이 회사는 AWS 클라우드에서 동일한 기능을 원합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

- A. 프로덕션 VPC에서 트래픽 검사 및 트래픽 필터링을 위해 Amazon GuardDuty를 사용합니다.
- B. 트래픽 미러링을 사용하여 프로덕션 VPC의 트래픽을 미러링하여 트래픽 검사 및 필터링을 수행합니다.
- C. AWS 네트워크 방화벽을 사용하여 프로덕션 VPC에 대한 트래픽 검사 및 트래픽 필터링에 필요한 규칙을 만듭니다.
- D. AWS Firewall Manager를 사용하여 프로덕션 VPC에 대한 트래픽 검사 및 트래픽 필터링에 필요한 규칙을 만듭니다.



> A15. AWS 네트워크 방화벽은 네트워크 트래픽을 필터링하고 검사하기 위한 방화벽 규칙을 정의할 수 있는 관리형 네트워크 방화벽 서비스입니다. 소스/대상 IP 주소, 프로토콜, 포트 등과 같은 다양한 기준에 따라 허용 또는 차단해야 하는 트래픽을 정의하는 규칙을 만들 수 있습니다. AWS 네트워크 방화벽을 사용하면 프로덕션 VPC 내에서 트래픽 검사 및 필터링 기능을 구현하여 네트워크 트래픽을 보호하는 데 도움이 됩니다. 주어진 시나리오의 맥락에서 AWS 네트워크 방화벽은 트래픽 미러링 없이 VPC 내에서 직접 트래픽 검사 및 필터링을 구현하려는 회사에 적합한 선택이 될 수 있습니다. 트래픽 필터링에 대한 특정 규칙을 적용하여 보안 계층을 추가로 제공하여 프로덕션 환경을 보호하는 데 도움이 될 수 있습니다. 옵션 A: Amazon GuardDuty는 트래픽 검사 또는 필터링 서비스가 아닌 위협 탐지 서비스입니다.옵션 B: 트래픽 미러링은 VPC에서 다른 VPC 또는 온프레미스 위치로 네트워크 트래픽 사본을 복제하여 보낼 수 있는 기능입니다.트래픽 검사 또는 필터링을 수행하는 서비스가 아닙니다.옵션 D: AWS Firewall Manager는 계정 전체에서 방화벽을 중앙에서 구성하고 관리하는 데 도움이 되는 보안 관리 서비스입니다.트래픽 검사 또는 필터링을 수행하는 서비스가 아닙니다. C

Q16. 한 회사가 AWS에서 데이터 레이크를 호스팅합니다. 데이터 레이크는 Amazon S3와 PostgreSQL용 Amazon RDS의 데이터로 구성됩니다. 이 회사는 **데이터 시각화를 제공**하고 데이터 레이크 내의 모든 데이터 소스를 포함하는 보고 솔루션이 필요합니다. 회사의 경영진만 모든 시각화에 대한 전체 액세스 권한을 가져야 합니다. 나머지 회사는 제한된 액세스 권한만 가져야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

- A. Amazon QuickSight에서 분석을 만듭니다. 모든 데이터 소스를 연결하고 새로운 데이터 세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 IAM 역할과 대시보드를 공유합니다.
- B. Amazon QuickSight에서 분석을 만듭니다. 모든 데이터 소스를 연결하고 새로운 데이터 세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 사용자 및 그룹과 대시보드를 공유합니다.
- C. Amazon S3의 데이터에 대한 AWS Glue 테이블과 크롤러를 만듭니다. AWS Glue 추출, 변환 및 로드(ETL) 작업을 만들어 보고서를 생성합니다. 보고서를 Amazon S3에 게시합니다. S3 버킷 정책을 사용하여 보고서에 대한 액세스를 제한합니다.
- D. Amazon S3의 데이터에 대한 AWS Glue 테이블과 크롤러를 만듭니다. Amazon Athena Federated Query를 사용하여 PostgreSQL용 Amazon RDS 내의 데이터에 액세스합니다. Amazon Athena를 사용하여 보고서를 생성합니다. 보고서를 Amazon S3에 게시합니다. S3 버킷 정책을 사용하여 보고서에 대한 액세스를 제한합니다.



> A16. 키워드: - AWS의 데이터 레이크. - Amazon S3 및 PostgreSQL용 Amazon RDS의 데이터로 구성됨. - 이 회사는 데이터 시각화를 제공하고 데이터 레이크 내의 모든 데이터 소스를 포함하는 보고 솔루션이 필요합니다. A - 오답: Amazon QuickSight는 사용자(표준 버전)와 그룹(엔터프라이즈 버전)만 지원합니다. 사용자와 그룹은 QuickSight 없이만 존재합니다. QuickSight는 IAM을 지원하지 않습니다. 사용자와 그룹을 사용하여 QuickSight 대시보드를 봅니다. B - 정답: 답변 A에서 설명한 대로 QuickSight를 사용하여 S3, RDS, Redshift, Aurora, Athena, OpenSearch, Timestream에서 대시보드를 만듭니다. C - 오답: 이 방법은 시각화를 지원하지 않으며 RDS 데이터를 처리하는 방법을 언급하지 않습니다. D - 오답: 이 방법은 시각화를 지원하지 않으며 RDS와 S3의 데이터를 결합하는 방법을 언급하지 않습니다. B

Q17. 한 회사가 **새로운 비즈니스** 애플리케이션을 구현하고 있습니다. 이 애플리케이션은 두 개의 Amazon EC2 인스턴스에서 실행되고 문서 저장을 위해 Amazon S3 버킷을 사용합니다. 솔루션 아키텍트는 EC2 인스턴스가 S3 버킷에 **액세스**할 수 있는지 확인해야 합니다.
솔루션 아키텍트는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

- A. S3 버킷에 대한 액세스를 허용하는 IAM 역할을 만듭니다. 역할을 EC2 인스턴스에 연결합니다.
- B. S3 버킷에 대한 액세스를 허용하는 IAM 정책을 만듭니다. 정책을 EC2 인스턴스에 연결합니다.
- C. S3 버킷에 대한 액세스를 허용하는 IAM 그룹을 만듭니다. 그룹을 EC2 인스턴스에 연결합니다.
- D. S3 버킷에 대한 액세스를 허용하는 IAM 사용자를 만듭니다. 사용자 계정을 EC2 인스턴스에 연결합니다.



> A17. 이 요구 사항을 충족하는 올바른 옵션은 A: S3 버킷에 대한 액세스 권한을 부여하는 IAM 역할을 만들고 EC2 인스턴스에 역할을 연결합니다. IAM 역할은 AWS 리소스와 서비스에 대한 액세스 권한을 위임할 수 있는 AWS 리소스입니다. S3 버킷에 대한 액세스 권한을 부여하는 IAM 역할을 만든 다음 EC2 인스턴스에 역할을 연결할 수 있습니다. 이렇게 하면 EC2 인스턴스가 S3 버킷과 그 안에 저장된 문서에 액세스할 수 있습니다. 옵션 B는 IAM 정책이 EC2 인스턴스가 아닌 IAM 사용자 또는 그룹에 대한 권한을 정의하는 데 사용되므로 올바르지 않습니다. 옵션 C는 IAM 그룹이 리소스에 대한 액세스 권한을 부여하는 것이 아니라 IAM 사용자와 정책을 그룹화하는 데 사용되므로 올바르지 않습니다. 옵션 D는 IAM 사용자가 리소스에 대한 액세스 권한을 부여하는 것이 아니라 AWS 리소스와 상호 작용하는 사람이나 서비스를 나타내는 데 사용되므로 올바르지 않습니다. A

Q18. 애플리케이션 개발팀은 큰 이미지를 더 작고 압축된 이미지로 변환하는 마이크로서비스를 설계하고 있습니다. 사용자가 웹 인터페이스를 통해 이미지를 업로드하면 마이크로서비스는 이미지를 Amazon S3 버킷에 저장하고, AWS Lambda 함수로 이미지를 처리하고 압축하고, 압축된 형태로 이미지를 다른 S3 버킷에 저장해야 합니다.
솔루션 아키텍트는 **내구성이 있고 상태 없는 구성 요소를 사용하여 이미지를 자동으로 처리**하는 솔루션을 설계해야 합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하십시오.)

- A. Amazon Simple Queue Service(Amazon SQS) 대기열을 만듭니다. 이미지가 S3 버킷에 업로드되면 SQS 대기열에 알림을 보내도록 S3 버킷을 구성합니다.
- B. Lambda 함수를 구성하여 Amazon Simple Queue Service(Amazon SQS) 대기열을 호출 소스로 사용합니다. SQS 메시지가 성공적으로 처리되면 대기열에서 메시지를 삭제합니다.
- C. Lambda 함수를 구성하여 S3 버킷에서 새 업로드를 모니터링합니다. 업로드된 이미지가 감지되면 파일 이름을 메모리의 텍스트 파일에 쓰고 텍스트 파일을 사용하여 처리된 이미지를 추적합니다.
- D. Amazon Simple Queue Service(Amazon SQS) 대기열을 모니터링하기 위해 Amazon EC2 인스턴스를 시작합니다. 대기열에 항목이 추가되면 EC2 인스턴스의 텍스트 파일에 파일 이름을 기록하고 Lambda 함수를 호출합니다.
- E. Amazon EventBridge(Amazon CloudWatch Events) 이벤트를 구성하여 S3 버킷을 모니터링합니다. 이미지가 업로드되면 Amazon Ample Notification Service(Amazon SNS) 토픽에 알림을 보내 추가 처리를 위해 애플리케이션 소유자의 이메일 주소를 입력합니다.

> 이미지를 자동으로 처리하기 위해 내구성 있는 상태 비저장 구성 요소를 사용하는 솔루션을 설계하기 위해 솔루션 아키텍트는 다음 작업을 고려할 수 있습니다. 옵션 A는 SQS 대기열을 만들고 이미지가 업로드될 때 대기열에 알림을 보내도록 S3 버킷을 구성하는 것입니다. 이를 통해 애플리케이션은 이미지 업로드 프로세스를 이미지 처리 프로세스에서 분리하고 새 이미지가 업로드될 때 이미지 처리 프로세스가 자동으로 트리거되도록 할 수 있습니다. 옵션 B는 Lambda 함수를 구성하여 SQS 대기열을 호출 소스로 사용하는 것입니다. SQS 메시지가 성공적으로 처리되면 메시지가 대기열에서 삭제됩니다. 이를 통해 Lambda 함수가 이미지당 한 번만 호출되고 이미지가 여러 번 처리되지 않습니다. AB

Q19. 한 회사에 AWS에 배포된 3계층 웹 애플리케이션이 있습니다. 웹 서버는 VPC의 퍼블릭 서브넷에 배포됩니다. 애플리케이션 서버와 데이터베이스 서버는 동일한 VPC의 프라이빗 서브넷에 배포됩니다. 이 회사는 검사 VPC에 AWS Marketplace의 타사 가상 방화벽 어플라이언스를 배포했습니다. 이 어플라이언스는 IP 패킷을 허용할 수 있는 IP 인터페이스로 구성되어 있습니다.
솔루션 아키텍트는 트래픽이 웹 서버에 도달하기 전에 애플리케이션에 대한 모든 트래픽을 검사하기 위해 웹 애플리케이션을 어플라이언스와 통합해야 합니다.
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요?

- A. 패킷 검사를 위해 트래픽을 어플라이언스로 라우팅하기 위해 애플리케이션의 VPC의 공개 서브넷에 네트워크 로드 밸런서를 생성합니다.
- B. 패킷 검사를 위해 트래픽을 어플라이언스로 라우팅하기 위해 애플리케이션 VPC의 공개 서브넷에 애플리케이션 부하 분산 장치를 생성합니다.
- C. 검사 VPC에 트랜싯 게이트웨이를 배포하고, 트랜싯 게이트웨이를 통해 들어오는 패킷을 라우팅하기 위한 경로 테이블을 구성합니다.
- D. 검사 VPC에 게이트웨이 로드 밸런서를 배포합니다. 게이트웨이 로드 밸런서 엔드포인트를 생성하여 들어오는 패킷을 수신하고 어플라이언스로 패킷을 전달합니다.